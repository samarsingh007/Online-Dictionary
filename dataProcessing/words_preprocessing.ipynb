{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import json\n",
    "from itertools import chain\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "212200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting all words that we have in NLTK & Webster\n",
    "allWords = set(chain(*[ss.lemma_names() for ss in wn.all_synsets()]))\n",
    "print(len(allWords))\n",
    "with open(\"dictionary_compact.json\",'r') as f:\n",
    "        data = json.load(f)\n",
    "for i in data:\n",
    "        allWords.add(i)        \n",
    "len(allWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all jsons line by line from wiktionary English Data\n",
    "\n",
    "\n",
    "\n",
    "lst = []\n",
    "with open(\"kaikki.org-dictionary-English.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        lst.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatUsage(body):\n",
    "    usageList = []\n",
    "    definitions = []\n",
    "    try:\n",
    "        \n",
    "        for i in body['senses']:\n",
    "            definition = i['glosses'][0].split('\\n') if 'glosses' in i else [\"\"]\n",
    "            definition = definition[0]\n",
    "            if definition in definitions:\n",
    "                continue\n",
    "            definitions.append(definition)\n",
    "\n",
    "            if 'examples' in i:\n",
    "                for j in i['examples']:\n",
    "                    j['source'] = 'Wiktionary'\n",
    "\n",
    "            examples = i['examples'] if 'examples' in i else []\n",
    "\n",
    "            usageList.append({\n",
    "                'definition': {\n",
    "                                'gloss':definition,\n",
    "                                'source':'Wiktionary',\n",
    "                },\n",
    "                'examples': examples\n",
    "            })\n",
    "    except:\n",
    "        return usageList\n",
    "    \n",
    "    return usageList\n",
    "\n",
    "def formatAudio(body):\n",
    "    audioList = []\n",
    "    if 'sounds' in body:\n",
    "        for j in body['sounds']:\n",
    "            if ('mp3_url' in j):\n",
    "                for i in audioList:\n",
    "                    if 'tags' in j and  i['tags'] == j['tags'][0]:\n",
    "                        continue\n",
    "                audioList.append({\n",
    "                    'audioLink': j['mp3_url'],\n",
    "                    'tags' : j['tags'][0] if 'tags' in j else \"\",\n",
    "                    'source': 'Wiktionary'\n",
    "\n",
    "                })\n",
    "    return audioList            \n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def formatObject(body):\n",
    "    return {\n",
    "        'pos'  : body['pos'],\n",
    "        'etymology_text' : body['etymology_text'] if 'etymology_text' in body else \"\",\n",
    "        'etymology_number' : body['etymology_number'] if 'etymology_number' in body else \"\",\n",
    "        'definitions': formatUsage(body),\n",
    "        'audio':formatAudio(body),\n",
    "        'source':'Wiktionary'\n",
    "\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124686\n"
     ]
    }
   ],
   "source": [
    "# Getting all objects/entries related to the word in payload\n",
    "payload= {}\n",
    "for i in lst:\n",
    "    word = i['word']\n",
    "    if word in allWords:\n",
    "        payload[word]= [formatObject(i)] if word not in payload else payload[word]+[formatObject(i)]\n",
    "print(len(payload))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalProcessedWords = []\n",
    "for i in payload:\n",
    "    finalProcessedWords.append({\n",
    "        'word':i,\n",
    "        'usage': payload[i]\n",
    "    })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(finalProcessedWords, indent=4)\n",
    "with open(\"websterWordNet.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting payload for each word in allWords in the required format for our database\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
