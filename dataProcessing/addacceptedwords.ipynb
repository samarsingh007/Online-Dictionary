{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code snippet performs an HTTP GET request to retrieve new words from a specific endpoint, parses the JSON response, and extracts the words from the response for further use or display.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import requests\nimport json\n\nurl = \"https://us-east-1.aws.data.mongodb-api.com/app/dictionary-eokle/endpoint/getNewWords?requestedState=Accepted\"\n\n\nheaders = {\n  'Content-Type': 'application/json'\n}\n\nresponse = requests.request(\"GET\", url, headers=headers, data=payload)\n\njson_list = json.loads(response.text)\n\nword_list = [json_obj['word'] for json_obj in json_list]\n\nprint(word_list)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T20:53:59.285322Z","iopub.execute_input":"2023-04-26T20:53:59.285734Z","iopub.status.idle":"2023-04-26T20:53:59.569365Z","shell.execute_reply.started":"2023-04-26T20:53:59.285699Z","shell.execute_reply":"2023-04-26T20:53:59.567905Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"['kya', 'IPL', 'newword123', 'sjixioj5678o690', 'heya', 'vev', 'vcsvf', 'head']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"this code snippet iterates over unique words and checks if each word exists in parsedWiktionary. If found, it sends a POST request to accept or reject the word and its corresponding usage data to a specific endpoint. The response from the request is then printed.","metadata":{}},{"cell_type":"code","source":"word_set = set(word_list)\nfor word in word_set:\n    if word in parsedWiktionary:\n        wordPayload = {\n        'word':word,\n        'usage': parsedWiktionary[word]\n    }\n        url = \"https://us-east-1.aws.data.mongodb-api.com/app/dictionary-eokle/endpoint/acceptRejectWord\"\n\n        payload = json.dumps({\n          \"word\": word,\n          \"state\": \"add\",\n          \"wordData\": wordPayload\n        })\n        headers = {\n      'Content-Type': 'application/json'\n    }\n\n        response = requests.request(\"POST\", url, headers=headers, data=payload)\n\n        print(response.text)\n  \n","metadata":{"execution":{"iopub.status.busy":"2023-04-26T20:54:12.156604Z","iopub.execute_input":"2023-04-26T20:54:12.157018Z","iopub.status.idle":"2023-04-26T20:54:12.165590Z","shell.execute_reply.started":"2023-04-26T20:54:12.156981Z","shell.execute_reply":"2023-04-26T20:54:12.163937Z"},"trusted":true},"execution_count":18,"outputs":[]}]}