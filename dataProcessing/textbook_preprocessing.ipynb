{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoOGZFSBiG-c",
        "outputId": "b5479d25-d54d-4bb7-d6aa-a7f4a2d27d39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from collections import defaultdict\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "def textrank(document):\n",
        "    # Tokenize the document into sentences and words\n",
        "    sentences = sent_tokenize(document)\n",
        "    words = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "    \n",
        "    # Remove stop words and punctuation\n",
        "    stop_words = set(stopwords.words('english') + list(punctuation))\n",
        "    words = [[word for word in sentence if word not in stop_words] for sentence in words]\n",
        "    \n",
        "    # Create a dictionary to store word frequency\n",
        "    frequency = defaultdict(int)\n",
        "    for sentence in words:\n",
        "        for word in sentence:\n",
        "            frequency[word] += 1\n",
        "            \n",
        "    # Calculate the word scores using Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "    tfidf = TfidfVectorizer().fit_transform(sentences)\n",
        "    cosine_similarities = cosine_similarity(tfidf)\n",
        "    \n",
        "    # Create a dictionary to store sentence scores\n",
        "    scores = defaultdict(int)\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        for j in range(len(sentences)):\n",
        "            if i != j:\n",
        "                scores[i] += cosine_similarities[i][j]\n",
        "    \n",
        "    # Normalize the scores\n",
        "    max_score = max(scores.values())\n",
        "    for sentence_index in scores:\n",
        "        scores[sentence_index] /= max_score\n",
        "        \n",
        "    # Sort the sentences by score in descending order\n",
        "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    # Return the most important sentence\n",
        "    return sentences[sorted_scores[0][0]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1tIFazWisKC",
        "outputId": "d3c4c386-d381-4c37-e1b2-076752dc2aef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "She closed the journal and began her preparation.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Example usage\n",
        "\n",
        "\n",
        "document = \"\"\"\n",
        "She ran to her desk and pulled out a journal, jotting down her latest symptom.\n",
        "If she didn't have a place she felt was safe enough, maybe she wrote her journal in code.\n",
        "Franke in two articles in the Journal of the Pali Text Society for 1903, and in his Geschichte and Kritik der einheimischen Pali Grammatik.\n",
        "Miss Annie's pretty much spelled it out in black and white in this here journal, even if it was in code.\n",
        "Every day, I write in a journal.\n",
        "Between Cynthia's and Donnie's efforts, only a few pages of the journal remained undeciphered.\n",
        "He glanced up at her, closing the journal.\n",
        "She closed the journal and began her preparation.\n",
        "His valuable notes on Indian dialects are in The Transactions of the American Philosophical Society (1862), in The American Journal of Science (1862) and in The Proceedings of the American Philosophical Society (1869).\n",
        "The Annie of Dean's dreams had long blonde hair but kept her head turned from him as she wrote in her journal.\n",
        "\"\"\"\n",
        "print(textrank(document))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0mtb6GYkDpX",
        "outputId": "f9c1783d-5153-4bb0-b3e1-e1134b4c31aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "austen-emma.txt\n",
            "austen-persuasion.txt\n",
            "austen-sense.txt\n",
            "bible-kjv.txt\n",
            "blake-poems.txt\n",
            "bryant-stories.txt\n",
            "burgess-busterbrown.txt\n",
            "carroll-alice.txt\n",
            "chesterton-ball.txt\n",
            "chesterton-brown.txt\n",
            "chesterton-thursday.txt\n",
            "edgeworth-parents.txt\n",
            "melville-moby_dick.txt\n",
            "milton-paradise.txt\n",
            "shakespeare-caesar.txt\n",
            "shakespeare-hamlet.txt\n",
            "shakespeare-macbeth.txt\n",
            "whitman-leaves.txt\n",
            "7752\n"
          ]
        }
      ],
      "source": [
        "import nltk \n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "gb = nltk.corpus.gutenberg\n",
        "\n",
        "for fileid in gb.fileids():\n",
        "  print(fileid)\n",
        "# print(\"Gutenberg files:n\", gb.fileids())\n",
        "sentences = gb.sents('austen-emma.txt')\n",
        "\n",
        "print(len(sentences))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFNutsXWJ10T"
      },
      "outputs": [],
      "source": [
        "rawtext = gb.raw('austen-emma.txt')\n",
        "processedtext = rawtext.replace('\\r','').replace('\\n',' ').replace('.\"','.').replace('Mr.','Mr').replace('Mrs.','Mr').replace('\"  ','.').replace('\"','').replace('W.', 'W').replace('_', '')\n",
        "sentencesarray = processedtext.split('.')\n",
        "sentencesarray = [s.strip() for s in sentencesarray]\n",
        "import re\n",
        "# sentencesarray = re.split(r'\\.|\\s{2}', sentences)\n",
        "# sentencesarray = sentences.split('   ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65FKWmoYNzBX"
      },
      "outputs": [],
      "source": [
        "for i in sentencesarray[300:600]:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpF11ymUotRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c297e911-689e-4835-8284-c2d751cdd04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pysolr\n",
            "  Downloading pysolr-3.9.0.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.9/dist-packages (from pysolr) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.9.1->pysolr) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.9.1->pysolr) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.9.1->pysolr) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.9.1->pysolr) (1.26.15)\n",
            "Building wheels for collected packages: pysolr\n",
            "  Building wheel for pysolr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysolr: filename=pysolr-3.9.0-py2.py3-none-any.whl size=19691 sha256=1e05899457494e2bc31926f6e84fc9a900611e3f39baa658f6b1889c0552ab69\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/e3/bb/f4c2a751045824a821ab25757e9762a66da88028d8f5f136ce\n",
            "Successfully built pysolr\n",
            "Installing collected packages: pysolr\n",
            "Successfully installed pysolr-3.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pysolr\n",
        "import pysolr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zirBF7FYo780",
        "outputId": "bfe56e32-1394-46d5-a37a-534c2bb5ab43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"responseHeader\":{\\n    \"zkConnected\":null,\\n    \"status\":0,\\n    \"QTime\":5,\\n    \"params\":{\\n      \"q\":\"{!lucene}*:*\",\\n      \"distrib\":\"false\",\\n      \"df\":\"_text_\",\\n      \"rows\":\"10\",\\n      \"echoParams\":\"all\",\\n      \"rid\":\"-60\"}},\\n  \"status\":\"OK\"}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "solr = pysolr.Solr('http://35.223.110.79:8983/solr/mycol1/', always_commit=True)\n",
        "\n",
        "solr.ping()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4ioxifspVkj"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "for index, value in enumerate(sentencesarray):\n",
        "  if len(value)<10:\n",
        "    continue\n",
        "  solr.add({\n",
        "        \"text\":value,\n",
        "        \"source\":\"Emma by Jane Austen\"\n",
        "  })\n",
        "  if index%150==0:\n",
        "    time.sleep(5)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uIq3RznBRyM"
      },
      "outputs": [],
      "source": [
        "text_file = open(\"burgess-final2.json\", \"w\")\n",
        "n = text_file.write('['+string+']')\n",
        "text_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Opjp4nQLhqGU",
        "outputId": "d9b3bed0-d298-41a0-a67f-d878cef869d7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-------------------------------------------------------------------------------'"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'-------------------------------------------------------------------------------'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOaX2fgyhsPn"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_file = zipfile.ZipFile('/content/660_webhose-2015-10-new_20170904095249.zip', 'r')\n",
        "zip_file.extractall('innerzip')\n",
        "zip_file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT3DN0kiirFu",
        "outputId": "2d1beef7-4a19-4ef7-8350-dc23d7c210ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['news_0010192.json', 'news_0084483.json', 'news_0081358.json', 'news_0076663.json', 'news_0012820.json', 'news_0005291.json', 'news_0055289.json', 'news_0080127.json', 'news_0030281.json', 'news_0031555.json', 'news_0042797.json', 'news_0030051.json', 'news_0023055.json', 'news_0063291.json', 'news_0077453.json', 'news_0057331.json', 'news_0077690.json', 'news_0027988.json', 'news_0027610.json', 'news_0084802.json', 'news_0024973.json', 'news_0001222.json', 'news_0011470.json', 'news_0067856.json', 'news_0047708.json', 'news_0018662.json', 'news_0059279.json', 'news_0002492.json', 'news_0016072.json', 'news_0012520.json', 'news_0079669.json', 'news_0074103.json', 'news_0081674.json', 'news_0078577.json', 'news_0072855.json', 'news_0051449.json', 'news_0004950.json', 'news_0074029.json', 'news_0084144.json', 'news_0053258.json', 'news_0081998.json', 'news_0031588.json', 'news_0020871.json', 'news_0069898.json', 'news_0006208.json', 'news_0051042.json', 'news_0060520.json', 'news_0057122.json', 'news_0009096.json', 'news_0010301.json', 'news_0063289.json', 'news_0073420.json', 'news_0079836.json', 'news_0076615.json', 'news_0080227.json', 'news_0021252.json', 'news_0026215.json', 'news_0046998.json', 'news_0014141.json', 'news_0000732.json', 'news_0044699.json', 'news_0027357.json', 'news_0082734.json', 'news_0031505.json', 'news_0020214.json', 'news_0015738.json', 'news_0023755.json', 'news_0032501.json', 'news_0069358.json', 'news_0075635.json', 'news_0019525.json', 'news_0004289.json', 'news_0034078.json', 'news_0055259.json', 'news_0059205.json', 'news_0024307.json', 'news_0059578.json', 'news_0054099.json', 'news_0013121.json', 'news_0047843.json', 'news_0071691.json', 'news_0018812.json', 'news_0001812.json', 'news_0021680.json', 'news_0023471.json', 'news_0021481.json', 'news_0009455.json', 'news_0050753.json', 'news_0053591.json', 'news_0017887.json', 'news_0082507.json', 'news_0081276.json', 'news_0017246.json', 'news_0038502.json', 'news_0064106.json', 'news_0065415.json', 'news_0070760.json', 'news_0086945.json', 'news_0064912.json', 'news_0025804.json']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import ast\n",
        "files = os.listdir('innerzip')\n",
        "print(files[:100])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "52j1hh8GHb5W",
        "outputId": "68b81f57-6c1f-4df1-aa4b-2efb2049a3bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<response>\\n\\n<lst name=\"responseHeader\">\\n  <int name=\"status\">0</int>\\n  <int name=\"QTime\">11</int>\\n</lst>\\n</response>\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "solr.delete(q='*:*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9oaftnutzbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a939b058-8ff1-443c-be8a-5725b1504886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentsplit in /usr/local/lib/python3.9/dist-packages (1.0.7)\n",
            "Requirement already satisfied: regex>=2021.10.23 in /usr/local/lib/python3.9/dist-packages (from sentsplit) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.59.0 in /usr/local/lib/python3.9/dist-packages (from sentsplit) (4.65.0)\n",
            "Requirement already satisfied: loguru>=0.5.3 in /usr/local/lib/python3.9/dist-packages (from sentsplit) (0.6.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.7 in /usr/local/lib/python3.9/dist-packages (from sentsplit) (0.9.9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-27 17:27:49.956 | INFO     | sentsplit.segment:__init__:47 - SentSplit for EN loaded:\n",
            "{ 'handle_multiple_spaces': True,\n",
            "  'maxcut': 500,\n",
            "  'mincut': 7,\n",
            "  'model': 'crf_models/en-default-25032021.model',\n",
            "  'ngram': 5,\n",
            "  'prevent_regexes': [ { 'name': 'liberal_url',\n",
            "                         'regex': '\\\\b((?:[a-z][\\\\w\\\\-]+:(?:\\\\/{1,3}|[a-z0-9%])|www\\\\d{0,3}[.]|[a-z0-9.\\\\-]+[.][a-z]{2,4}\\\\/)(?:[^\\\\s()<>]|\\\\((?:[^\\\\s()<>]|(?:\\\\([^\\\\s()<>]+\\\\)))*\\\\))+(?:\\\\((?:[^\\\\s()<>]|(?:\\\\([^\\\\s()<>]+\\\\)))*\\\\)|[^\\\\s`!()\\\\[\\\\]{};:\\\\\\'\".,<>?«»“”‘’]))'},\n",
            "                       { 'name': 'period_followed_by_lowercase',\n",
            "                         'regex': '\\\\.(?= *[a-z])'}],\n",
            "  'prevent_word_split': True,\n",
            "  'segment_regexes': [ {'at': 'end', 'name': 'after_semicolon', 'regex': ' *;'},\n",
            "                       { 'at': 'end',\n",
            "                         'name': 'ellipsis',\n",
            "                         'regex': '…(?![\\\\!\\\\?\\\\.．？！])'},\n",
            "                       {'at': 'end', 'name': 'newline', 'regex': '\\\\n'}],\n",
            "  'strip_spaces': False}\n"
          ]
        }
      ],
      "source": [
        "!pip install sentsplit\n",
        "from sentsplit.segment import SentSplit\n",
        "sent_splitter = SentSplit('en')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x3yyBrADIM65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "2ILFz_oTDUgI",
        "outputId": "f9522095-85ae-4692-82ed-dbaa58fcd3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0 files\n",
            "Processed 500 files\n",
            "Processed 1000 files\n",
            "Processed 1500 files\n",
            "Processed 2000 files\n",
            "Processed 2500 files\n",
            "Processed 3000 files\n",
            "Processed 3500 files\n",
            "Processed 4000 files\n",
            "Processed 4500 files\n",
            "Processed 5000 files\n",
            "Processed 5500 files\n",
            "Processed 6000 files\n",
            "Processed 6500 files\n",
            "Processed 7000 files\n",
            "Processed 7500 files\n",
            "Processed 8000 files\n",
            "Processed 8500 files\n",
            "Processed 9000 files\n",
            "Processed 9500 files\n",
            "Processed 10000 files\n",
            "Processed 10500 files\n",
            "Processed 11000 files\n",
            "Processed 11500 files\n",
            "Processed 12000 files\n",
            "Processed 12500 files\n",
            "Processed 13000 files\n",
            "Processed 13500 files\n",
            "Processed 14000 files\n",
            "Processed 14500 files\n",
            "Processed 15000 files\n",
            "Processed 15500 files\n",
            "Processed 16000 files\n",
            "Processed 16500 files\n",
            "Processed 17000 files\n",
            "Processed 17500 files\n",
            "Processed 18000 files\n",
            "Processed 18500 files\n",
            "Processed 19000 files\n",
            "Processed 19500 files\n",
            "Processed 20000 files\n",
            "Processed 20500 files\n",
            "Processed 21000 files\n",
            "Processed 21500 files\n",
            "Processed 22000 files\n",
            "Processed 22500 files\n",
            "Processed 23000 files\n",
            "Processed 23500 files\n",
            "Processed 24000 files\n",
            "Processed 24500 files\n",
            "Processed 25000 files\n",
            "Processed 25500 files\n",
            "Processed 26000 files\n",
            "Processed 26500 files\n",
            "Processed 27000 files\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"responseHeader\":{\\n    \"status\":0,\\n    \"QTime\":169}}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "folder_path = 'innerzip'\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Loop over each file in the folder\n",
        "for index, filename in enumerate(sorted(os.listdir(folder_path))[60001:]):\n",
        "    \n",
        "    # Check if the file is a JSON file\n",
        "    if filename.endswith('.json'):\n",
        "        # Construct the full path to the file\n",
        "        filepath = os.path.join(folder_path, filename)\n",
        "        # Open the file for reading\n",
        "        with open(filepath, 'r') as f:\n",
        "            # print(filepath)\n",
        "            # Load the JSON data from the file\n",
        "            data = json.load(f)\n",
        "            \n",
        "            # print(data)\n",
        "            # Perform operations on the data here\n",
        "            # ...\n",
        "            # print(json.dumps(data, indent=4))\n",
        "            source = data['thread']['site']\n",
        "            rawtext = data['text']\n",
        "            # print(source)\n",
        "\n",
        "            # proc_text = (rawtext.replace(\"\\\\\",\"\").replace('\\n','   ').replace('\"',\"'\").replace('D.C.','DC')\n",
        "            # .replace('U.S.','US').replace('Mr.','Mr').replace('Mrs.','Mrs').replace('.com','com')\n",
        "            # .replace('Jan.','Jan').replace('Feb.','Feb').replace('Mar.','Mar').replace('Apr.','Apr').replace('May.','May').replace('Jun.','Jun')\n",
        "            # .replace('Jul.','Jul').replace('Aug.','Aug').replace('Sep.','Sep').replace('Oct.','Oct').replace('Nov.','Nov').replace('Dec.','Dec')\n",
        "            # .replace('Rep.','Rep').replace('Sen.','Sen').replace('Dem.','Dem').replace('p.m.','pm').replace('P.M.','PM').replace('a.m.','am')\n",
        "            # .replace('A.M.','AM').replace('www.','www'))\n",
        "            proc_sentences = sent_splitter.segment(rawtext.replace(\"\\\\\",\"\").replace('\\n','   '))\n",
        "            # print(proc_text)\n",
        "            # proc_sentences = proc_text.split('.')\n",
        "            \n",
        "            for sent in proc_sentences:\n",
        "              if len(sent)<1:\n",
        "                continue\n",
        "              tosolr.append({'text':sent.strip(), 'source':source, 'processed':'27Mar'})\n",
        "              # print(tosolr)\n",
        "            if(len(tosolr)>1000):\n",
        "              solr.add(tosolr)\n",
        "              tosolr=[]\n",
        "            # print(tosolr)\n",
        "            # print(source)\n",
        "            if index%500==0:\n",
        "              print('Processed '+str(index)+' files')\n",
        "            \n",
        "solr.add(tosolr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmhdmfyjjcz8",
        "outputId": "80986fd3-54cd-4a5d-ab4a-09cadbe66a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Watching the conventional media’s coverage of the 2016 presidential race is disheartening, to put it lightly', ' The personality politics, appealing to the emotions of voters rather than their reason and intellect, tell a story all too familiar for the United States', ' ', 'Take for example the Republican Party’s frontrunners Donald Trump and Jeb Bush', ' ', 'One could think of a plethora of reasons to criticize the former governor of Florida: his undying support for big banks that precipitated the collapse of the economy; his avowed commitment to the construction of more prisons and harsher sentences to non-violent offenders that cost taxpayers more money and perpetuate recidivism; his plans to defund programs and organizations that are often the only places women can turn for healthcare and reproductive services', ' ', 'Yet, rather than offering any criticism of substance, Mr Trump invoked Mr Bush’s \"low-energy\" in order to get ahead in the polls, a telling signal that many people are more concerned with mudslinging than with discussion of the real issues and policies that could potentially revive our flagging democracy', ' ', 'Equally disappointing is the fact that potential Democratic nominee Hillary Clinton is using the same kind of empty, vapid attacks to gain ground on US Sen Bernie Sanders (D-VT)', ' Her super PAC, Correct the Record, circulated assaults on Sanders’ support of newly-elected Labour Party official Jeremy Corbyn in Britain and made unfounded comparisons of the senator to the late-socialist President Hugo Chavez of Venezuela', ' ', 'But the most discouraging reality in this upcoming election lies in our illusion of choice', ' Looking below the surface of the childish name-calling characteristic of contemporary politics, the moneyed influence of our nation’s largest corporations becomes apparent', ' ', 'Take, for instance, the fact that the top donors to Jeb Bush are the same as Hilary Clinton’s, ie Citigroup and Goldman Sachs, the banking giants that were central to the 2008 financial and economic crisis', ' That crisis precipitated the collapse of the global economy with toxic mortgage securities and rigged credit ratings, which led to massive unemployment and homelessness', ' ', 'It becomes apparent whose interests are being met by both party’s representatives when illuminating the sources of their campaign money', ' ', 'Private equity executive and Cuban refugee Miguel Fernandez’s donation of $3 million to Bush’s super PAC Right to Rise was followed by Bush’s criticism of Obama’s reconciliation with Cuba', ' And former Secretary of State Clinton’s campaign has received enormous amounts of money and lobbying from the biggest players in the fossil fuel industries', ' Her promise to focus on reducing fossil fuel dependence is weakened in light of her principal donors', ' ', 'Almost all candidates’ support for the Trans-Pacific Partnership, or TPP, demonstrates the massive reach that moneyed interests have on our nation’s politics', ' This trade agreement is forecasted to move more jobs out of the United States in the all too familiar corporate race-to-the-bottom and gut environmental and consumer regulations that guarantee the safety of our planet and people for the benefit of big business', ' ', 'So the question remains: Who, if anyone, is there that is not in the pocket of the affluent few and will fight to represent the interests and needs of everyday people and our communities? ', 'Progressive hopeful Bernie Sanders’ funding for his campaign stands out in sharp contrast from the political establishment’s candidates', ' Receiving the majority of his money from small donations given by everyday people, grassroots organizations and unions, the senator offers a glimmer of hope that there are still representatives of and for average citizens', ' ', 'His ardent criticism of income inequality generated by corporate welfare is reflected in his voting record, in which he has proved his commitment to working towards a fairer and more equal future', ' His appeal is felt wherever he goes on the campaign trail with troves of people coming out to hear him speak', ' ', 'But a disappointing reality is that some candidates are left out of the debate all together, even though their message is one that many people have been craving', ' Green Party candidate Jill Stein is one such candidate', ' ', 'Stein has vocally made clear her platform to work for the betterment of ordinary citizens, whose voices have been stifled in the tumult of wealthy concerns', ' ', 'Running in the 2012 presidential election on the Green Party ticket, Harvard-educated Stein put forth her program aimed at reforming our political and economic quandaries deemed the \"Green New Deal', '\" The four-part program calls for an economic bill of rights that would protect against the interests of big business in politics while guaranteeing employment, healthcare, affordable housing and tuition-free college education; a transition to an economy that values environmental and social sustainability; reformation of our financial sector; and the reorganization of electoral politics to promote a truly democratic process', ' ', 'The author is a Bloomfield resident and Montclair State University senior', '']\n"
          ]
        }
      ],
      "source": [
        "source = (data['thread']['site'])\n",
        "fulltext = data['text']\n",
        "import re\n",
        "texts = (re.split('\\n|\\.', fulltext.replace('Mr.','Mr').replace('U.S.','US').replace('Sen.', 'Sen').replace('i.e.', 'ie')))\n",
        "``\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUdnSaxMUdSR",
        "outputId": "a999774a-2fc9-4c99-d0c2-c2a302f5a379"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n"
          ]
        }
      ],
      "source": [
        "print(len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9S8x_DpUjU9",
        "outputId": "f06297e7-ca97-40b8-af04-6b22ad17ce5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Treasury Secretary Jack Lew warned Congress on Thursday that it must raise the debt ceiling by Nov 3 in order to guarantee that the government will be able to avoid a default on the debt.\n",
            "Lew's letter makes the debt ceiling a more urgent matter than it already was for Congress.\n",
            "Previously, Lew had warned that he would exhaust the 'extraordinary measures' he's using to make payments under the $18.1 trillion debt limit on Nov 5.\n",
            "Now, he warned, he expects to be left with no resources except for $30 billion in cash after Nov 3, less than three weeks away.\n",
            "Related Story: http://www.washingtonexaminercom/article/2574118/.\n",
            "Lew's message will increase the pressure on outgoing House Speaker John Boehner, R-Ohio, to raise the debt ceiling before his planned retirement at the end of October.\n",
            "Republicans have yet to select a new speaker after Majority Leader Kevin McCarthy, R-Calif., bowed out of the race, which means Republicans may be hamstrung in dealing with the debt ceiling until they find a new leader.\n",
            "Complicating it further, many conservative members of the House won't want to raise the debt ceiling unless it's part of a deal to cut spending further.\n",
            "McCarthy warns against Obama's drawdown in Afghanistan House Majority Leader Kevin McCarthy praised President Obama's decision to keep troops in Afghanistan Thursday, but warned against an 'arbitrary drawdown' in 2016.\n",
            "McCarthy, R-Calif., issued a statement following Obama's Thursday announcement that he was delaying plans to pull all American troops out of Afghanistan by the end of his term.\n",
            "Instead, Obama said he would keep nearly 9,800 troops in the region until October 2016 and then cut back to 5,500 troops in early 2017.\n",
            "McCarthy warned against the planned reduction, citing Taliban gains in Afghanistan.\n",
            "'The president should not continue his arbitrary troop drawdown from 9,800 troops to 5,500 in 2016 until conditions on the ground and US national securityBy Susan Ferrechio • 10/15/15 12:59 PM Lew has been managing government accounts to pay incoming bills without raising the debt ceiling since March, when a previous suspension of the debt ceiling ended.\n",
            "Once all the tools for managing the debt to keep it below the ceiling are exhausted, he will only have cash on hand and incoming revenues to pay for the government's bills.\n",
            "The Congressional Budget Office estimated Wednesday that the Treasury would face the possibility of missing a payment on the debt or on another obligation 'sometime during the first half of November.\n"
          ]
        }
      ],
      "source": [
        "for i in sentences:\n",
        "  print(i.strip())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}