{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from nltk.corpus import wordnet as wn\nimport json\nfrom itertools import chain\nimport json\nimport nltk\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('omw-1.4')\nnltk.download('wordnet')\nnltk.download('wordnet2022')\nnltk.download('words')\n!pip install language-tool-python\nimport language_tool_python\nimport re\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\n!pip install --upgrade gingerit\nimport gingerit\n\n\n\n\n! cp -rf /usr/share/nltk_data/corpora/wordnet2022 /usr/share/nltk_data/corpora/wordnet # temp fix for lookup error","metadata":{"execution":{"iopub.status.busy":"2023-05-17T02:25:57.379640Z","iopub.execute_input":"2023-05-17T02:25:57.380007Z","iopub.status.idle":"2023-05-17T02:26:34.831140Z","shell.execute_reply.started":"2023-05-17T02:25:57.379977Z","shell.execute_reply":"2023-05-17T02:26:34.829783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentence PreProcessing\n\n**`is_proper_english(sentence)`**: This function checks if a given sentence is considered proper English. It tokenizes the sentence into individual words, tags each word with its part of speech using NLTK, and then verifies if all words are recognized as English words with valid parts of speech. The function returns `True` if the sentence is considered proper English, and `False` otherwise.\n\n**`check_english_sentence(sentence)`**: This function checks if a sentence is written in English. It removes non-alphabetic characters, converts the sentence to lowercase, and uses the `nlp` object from SpaCy to process the sentence. It then verifies that each token in the processed sentence is composed of alphabetic ASCII characters and has the language attribute set to \"en\" (English). The function returns `True` if all tokens in the sentence are determined to be English, and `False` otherwise.\n\n**`remove_symbols(sentence)`**: This function removes symbols and special characters from a given sentence while retaining parentheses, semicolons, exclamation marks, and quotation marks. It uses regular expressions to perform the removal and returns the modified sentence.\n\n**`correct_sentence(sentence)`**: This function utilizes the LanguageTool library to correct grammatical errors in a given sentence. It takes the sentence as input, applies language-based rules to identify and correct errors, and returns the corrected sentence.\n\nBy using these functions, you can ensure the proper validation, cleaning, and correction of sentences in your language processing tasks.","metadata":{}},{"cell_type":"code","source":"def is_proper_english(sentence):\n    # Download the necessary resources for the NLTK library\n    \n    \n    # Tokenize the sentence into individual words\n    words = nltk.word_tokenize(sentence)\n    \n    # Tag each word with its part of speech\n    tagged_words = nltk.pos_tag(words)\n    \n    # Check if all words are recognized as English words and their corresponding part of speech is valid\n    for word, tag in tagged_words:\n        if not word.isalpha() or tag not in ['JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS', 'RB', 'RBR', 'RBS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n            return False\n    \n    return True\n\n# def check_english_sentence(sentence):\n#     sentence = re.sub(r'[^\\w\\s]', ' ', sentence)\n\n#     # Remove extra whitespace and convert to lowercase\n#     sentence = re.sub(r'\\s+', ' ', sentence).strip().lower()\n#     words = nltk.word_tokenize(sentence)\n#     print(words)\n#     english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n#     return all(word.lower() in english_vocab for word in words)\n\ndef check_english_sentence(sentence):\n    sentence = re.sub(r'[^\\w\\s]', ' ', sentence)\n    sentence = re.sub(r'\\s+', ' ', sentence).strip().lower()\n    doc = nlp(sentence)\n\n    return all(token.is_alpha and token.is_ascii and token.lang_ == \"en\" for token in doc)\ndef remove_symbols(sentence):\n    # remove mathematical symbols\n    sentence = re.sub(r'[+\\-*\\/=<>]', '', sentence)\n\n    # remove currency symbols\n#     sentence = re.sub(r'[£€¥$]', '', sentence)\n\n    # remove special characters except for parentheses, semicolons, exclamation marks, and quotation marks\n    sentence = re.sub(r'[^\\w\\s();!\"\\']', '', sentence)\n\n    return sentence\n\ndef correct_sentence(sentence):\n    tool = language_tool_python.LanguageTool('en-US')\n    corrected = tool.correct(sentence)\n    return corrected\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T02:27:08.621271Z","iopub.execute_input":"2023-05-17T02:27:08.621644Z","iopub.status.idle":"2023-05-17T02:27:08.639332Z","shell.execute_reply.started":"2023-05-17T02:27:08.621616Z","shell.execute_reply":"2023-05-17T02:27:08.638175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting all jsons line by line from wiktionary English Data\n","metadata":{}},{"cell_type":"code","source":"# Getting all jsons line by line from wiktionary English Data\n\n\n\nlst = []\nwith open(\"/kaggle/input/wiktionarywebster/kaikki.org-dictionary-English.json\", \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        data = json.loads(line)\n        lst.append(data)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T02:27:15.416665Z","iopub.execute_input":"2023-05-17T02:27:15.417209Z","iopub.status.idle":"2023-05-17T02:28:22.870315Z","shell.execute_reply.started":"2023-05-17T02:27:15.417181Z","shell.execute_reply":"2023-05-17T02:28:22.869444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting the list of credible words from NLTK & Webster","metadata":{}},{"cell_type":"code","source":"# Getting all words that we have in NLTK & Webster\nallWords = set(chain(*[ss.lemma_names() for ss in wn.all_synsets()]))\nprint(len(allWords))\nwith open(\"/kaggle/input/wiktionarywebster/dictionary_compact.json\",'r') as f:\n        data = json.load(f)\nfor i in data:\n        allWords.add(i)        \nlen(allWords)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T02:28:34.094429Z","iopub.execute_input":"2023-05-17T02:28:34.094837Z","iopub.status.idle":"2023-05-17T02:28:41.467513Z","shell.execute_reply.started":"2023-05-17T02:28:34.094805Z","shell.execute_reply":"2023-05-17T02:28:41.466525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:11:23.798274Z","iopub.execute_input":"2023-04-27T06:11:23.799065Z","iopub.status.idle":"2023-04-27T06:11:23.809169Z","shell.execute_reply.started":"2023-04-27T06:11:23.799012Z","shell.execute_reply":"2023-04-27T06:11:23.807779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function which will link every json to the word it belongs\nThe `formatUsage(body)` function is responsible for processing the data and extracting a JSON structure containing the definitions and examples of a word. It iterates over the senses in the provided `body` and extracts the first gloss (definition) from each sense. If an example is available, it removes symbols from the example text and filters out non-English examples. The resulting data is then appended to the `usageList` list, which contains objects representing each definition with its corresponding examples.\n\nThe `formatAudio(body)` function processes the data and extracts a JSON structure containing audio links for the word. It checks if the provided `body` contains sounds, and if so, it iterates over the sounds and extracts the `mp3_url` and `tags` (if available) for each sound. The extracted audio data is appended to the `audioList` list, ensuring that duplicate tags are not included.\n\nThe `formatIPA(body)` function extracts the International Phonetic Alphabet (IPA) representation of the word from the provided `body`. It checks if the `body` contains sounds and if any of the sounds have an `ipa` attribute. If found, the IPA representation is stored in the `ipa` variable.\n\nThe `formatObject(body)` function utilizes the aforementioned functions and processes the provided `body` to create a formatted JSON object representing the word. It extracts the part of speech, etymology text and number (if available), definitions with examples, audio links, IPA representation, and the source (Wiktionary) for the word. The resulting JSON object is returned.\n\nBy utilizing these functions, you can preprocess the data and extract relevant information from the webster source, ensuring a structured representation of the word's definitions, examples, audio links, IPA, and other details from Wiktionary.","metadata":{}},{"cell_type":"code","source":"def formatUsage(body):\n    usageList = []\n    definitions = []\n    try:\n        \n        for i in body['senses']:\n            definition = i['glosses'][0].split('\\n') if 'glosses' in i else [\"\"]\n            definition = definition[0]\n            if definition in definitions:\n                continue\n            definitions.append(definition)\n\n            if 'examples' in i:\n                for j in i['examples']:\n                    j['source'] = 'Wiktionary'\n                    j['text'] = remove_symbols(j['text'])\n\n            examples = i['examples'] if 'examples' in i else []\n            filtered_data = list(filter(lambda x: check_english_sentence(x['text']) , examples))\n\n            usageList.append({\n                'definition': {\n                                'gloss':definition,\n                                'source':'Wiktionary',\n                },\n                'examples': filtered_data\n            })\n    except:\n        return usageList\n    \n    return usageList\n\ndef formatAudio(body):\n    audioList = []\n    if 'sounds' in body:\n        \n        for j in body['sounds']:\n            if ('mp3_url' in j):\n                for i in audioList:\n                    if 'tags' in j and  i['tags'] == j['tags'][0]:\n                        continue\n                \n                audioList.append({\n                    'audioLink': j['mp3_url'],\n                    'tags' : j['tags'][0] if 'tags' in j else \"\",\n                    'source': 'Wiktionary',\n                    \n\n                })\n                \n    return audioList\n\ndef formatIPA(body):\n    ipa = \"\"\n    if 'sounds' in body:\n      \n        for j in body['sounds']:\n            if ('ipa' in j):\n                ipa = j['ipa']\n                \n                \n    return ipa\n\n\n\n\n\n\n\n    \n\ndef formatObject(body):\n    return {\n        'pos'  : body['pos'],\n        'etymology_text' : body['etymology_text'] if 'etymology_text' in body else \"\",\n        'etymology_number' : body['etymology_number'] if 'etymology_number' in body else \"\",\n        'definitions': formatUsage(body),\n        'audio':formatAudio(body),\n        'ipa':formatIPA(body),\n        'source':'Wiktionary'\n        \n\n    }\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-17T02:45:38.620749Z","iopub.execute_input":"2023-05-17T02:45:38.621140Z","iopub.status.idle":"2023-05-17T02:45:38.635170Z","shell.execute_reply.started":"2023-05-17T02:45:38.621105Z","shell.execute_reply":"2023-05-17T02:45:38.633981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting all objects/entries related to the word in payload and associating them to word using above function","metadata":{}},{"cell_type":"code","source":"# Getting all objects/entries related to the word in payload\npayload= {}\ncount = 0\nfor i in lst[:]:\n    word = i['word']\n    if word in allWords:\n        payload[word]= [formatObject(i)] if word not in payload else payload[word]+[formatObject(i)]\n        \n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-17T03:01:40.952797Z","iopub.execute_input":"2023-05-17T03:01:40.953126Z","iopub.status.idle":"2023-05-17T03:28:20.002973Z","shell.execute_reply.started":"2023-05-17T03:01:40.953100Z","shell.execute_reply":"2023-05-17T03:28:20.001814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This block will build the an array of json which can be loaded to a non sql database directly","metadata":{}},{"cell_type":"code","source":"finalProcessedWords = []\nfor i in payload:\n    finalProcessedWords.append({\n        'word':i,\n        'usage': payload[i],\n        'type': 'word_data'\n    })\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T03:39:25.020834Z","iopub.execute_input":"2023-05-17T03:39:25.021175Z","iopub.status.idle":"2023-05-17T03:39:25.279083Z","shell.execute_reply.started":"2023-05-17T03:39:25.021149Z","shell.execute_reply":"2023-05-17T03:39:25.277691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For Dumping the Araay to a json file","metadata":{}},{"cell_type":"code","source":"json_object = json.dumps(finalProcessedWords, indent=4)\nwith open(\"sample.json\", \"w\") as outfile:\n    outfile.write(json_object)        \n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T03:40:12.788265Z","iopub.execute_input":"2023-05-17T03:40:12.788653Z","iopub.status.idle":"2023-05-17T03:40:23.522330Z","shell.execute_reply.started":"2023-05-17T03:40:12.788624Z","shell.execute_reply":"2023-05-17T03:40:23.521551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-04-26T20:17:12.491802Z","iopub.execute_input":"2023-04-26T20:17:12.492191Z","iopub.status.idle":"2023-04-26T20:17:24.388950Z","shell.execute_reply.started":"2023-04-26T20:17:12.492159Z","shell.execute_reply":"2023-04-26T20:17:24.388064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-04-26T20:21:21.174840Z","iopub.execute_input":"2023-04-26T20:21:21.175553Z","iopub.status.idle":"2023-04-26T20:21:21.182700Z","shell.execute_reply.started":"2023-04-26T20:21:21.175509Z","shell.execute_reply":"2023-04-26T20:21:21.181208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"/kaggle/working/sample.json\"> Download File </a>\n","metadata":{}}]}